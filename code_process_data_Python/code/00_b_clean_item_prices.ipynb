{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721465ef",
   "metadata": {},
   "source": [
    "# Extract and clean food prices over times using information compiled in the Item Price Diff "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b5c1e",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d77443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3d1c7",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73792166",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read food to calories docuements\n",
    "## Information important for the next steps:\n",
    "food_information =  pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Food to Calories/food_names_and_calories.xlsx')\n",
    "food_information['possible_name'] = [x.lower().strip(' ').replace(\" \", '_') if type(x) == str else np.nan for x in food_information['possible_name']]\n",
    "food_information['food_name'] = np.array([x.lower().strip(' ').replace(\" \", '_') for x in food_information['food_name']])\n",
    "potential_name = np.append(np.array(food_information['possible_name'].dropna()), np.array(food_information['food_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cda37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.ExcelFile('../../1. Data available/ISHTM_Hadhreen/Kitchen Admin Documents/Item Prices Diff.xlsx')\n",
    "nb_sheets = len(excel_file.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3aeb7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.DataFrame(columns=[\"kitchen_id\", \"type_of_food\", \"date\", \"price\"])\n",
    "for nb_sheet in range(nb_sheets):\n",
    "    df_price = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Kitchen Admin Documents/Item Prices Diff.xlsx', sheet_name=nb_sheet)\n",
    "    ## First extract kichen_ID\n",
    "    matches = df_price.apply(lambda x: x.astype(str).str.contains(r'\\bKitchen ID\\b', case=False, na=False))\n",
    "    locations_kitchen_id = [(row_idx, col_idx) for row_idx, col in matches.iterrows() for col_idx, match in enumerate(col) if match]\n",
    "    if(len(locations_kitchen_id) == 0):\n",
    "        continue\n",
    "    kitchen_id = df_price.iloc[locations_kitchen_id[0][0], locations_kitchen_id[0][1] +1]\n",
    "    \n",
    "    ## Than clean the rest\n",
    "    matches = df_price.apply(lambda x: x.astype(str).str.contains(r'\\bDescription\\b', case=False, na=False))\n",
    "    # Extract row and column indices\n",
    "    locations_description = [(row_idx, col_idx) for row_idx, col in matches.iterrows() for col_idx, match in enumerate(col) if match]\n",
    "    \n",
    "    # Check for the word \"TOTAL\"\n",
    "    matches = df_price.apply(lambda x: x.astype(str).str.contains(r'\\Dec\\b', case=False, na=False))\n",
    "    # Extract row and column indices\n",
    "    locations_dec = [(row_idx, col_idx) for row_idx, col in matches.iterrows() for col_idx, match in enumerate(col) if match]\n",
    "    \n",
    "    # Extract only information\n",
    "    price_extract = df_price.iloc[locations_description[0][0]:,locations_description[0][1]:locations_dec[0][1]+2]\n",
    "    #price_extract = price_extract.dropna(axis=1, how='all')\n",
    "    \n",
    "    #Change column name\n",
    "    price_extract.columns = price_extract.iloc[0]\n",
    "    price_extract = price_extract.drop(price_extract.index[0])\n",
    "    \n",
    "    # Rename columns\n",
    "    price_extract.columns = ['description', 'unit', '01/07/2024', '15/07/2024', '01/08/2024', '15/08/2024',\n",
    "                             '01/09/2024', '15/09/2024','01/10/2024', '15/10/2024', '01/11/2024', '15/11/2024',\n",
    "                             '01/12/2024', '15/12/2024']\n",
    "    \n",
    "    ## Remove na column description\n",
    "    price_extract = price_extract.dropna(subset=['description'])\n",
    "    \n",
    "    # now remove information not corresponding to food \n",
    "    # Filter to keep only English words\n",
    "    price_extract['description'] = [[word.lower().strip(' ').replace(\" \", '_') for word in pair if re.match(r'^[a-zA-Z\\s]+$', word)] for pair in [x.split('/') for x in np.array(price_extract['description'])]]\n",
    "    price_extract['description']  = [x[0] for x in price_extract['description']]\n",
    "    \n",
    "    # Only select lines when the description is corresponding to a food name (ex not transportation)\n",
    "    price_extract = price_extract[price_extract['description'].isin(potential_name)]\n",
    "    price_extract['description'] = [x if x in np.array(food_information['food_name']) else np.array(food_information[food_information['possible_name'] == x]['food_name'])[0] for x in price_extract['description']] \n",
    "    \n",
    "    ##Transform the data into a long data\n",
    "    price_extract[\"kitchen_id\"] = kitchen_id\n",
    "    \n",
    "    ##Drop unit columns\n",
    "    price_extract = price_extract.drop('unit', axis=1)\n",
    "    \n",
    "    # Reshape DataFrame from wide to long format\n",
    "    df_long = pd.melt(\n",
    "        price_extract,\n",
    "        id_vars=[\"kitchen_id\", \"description\"],\n",
    "        var_name=\"date\",\n",
    "        value_name=\"price\"\n",
    "    )\n",
    "    \n",
    "    # Drop rows where price is NaN\n",
    "    df_long = df_long.dropna(subset=[\"price\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Reorganize columns\n",
    "    df_long = df_long[[\"kitchen_id\", \"description\", \"date\", \"price\"]]\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df_long = df_long.rename(columns={\"description\": \"type_of_food\"})\n",
    "\n",
    "    final_results = pd.concat([final_results, df_long], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8c0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First remove kitchen ids with nan\n",
    "final_results = final_results[final_results['kitchen_id'].notna()]\n",
    "## Extract only the first element when there is a comma - split \n",
    "final_results['kitchen_id'] = [str(name).split(',')[0] for name in final_results['kitchen_id']]\n",
    "## Upload kitchen_id_localisation file\n",
    "kitchen_data = pd.read_excel('../output/kitchen_ids_cluster.xlsx')\n",
    "## Merge final_results with this file\n",
    "final_results = pd.merge(final_results, kitchen_data[['kitchen_code', 'kitchen_locality']], left_on='kitchen_id', right_on='kitchen_code', how='left') \n",
    "final_results = final_results[['type_of_food', 'date', 'price', 'kitchen_code','kitchen_locality']]\n",
    "\n",
    "##Kitchen not in service\n",
    "kitchen_to_be_removed = ['KH/JA/184', 'KH/JA/185', 'KH/JA/186', 'KH/JA/187', 'KH/JA/188', 'KH/JA/189', 'KH/JA/190', 'KH/JA/191',\n",
    "                         'KH/JA/192', 'KH/JA/193', 'KH/JA/194', 'KH/JA/195', 'KH/JA/196', 'KH/JA/197', 'KH/JA/198', 'KH/JA/199',\n",
    "                         'KH/JA/200', 'KH/JA/201', 'KH/JA/202', 'KH/JA/203', 'KH/JA/204', 'KH/JA/205', 'KH/JA/206', 'KH/JA/207',\n",
    "                         'KH/JA/208', 'KH/JA/209', 'KH/JA/210', 'KH/JA/211', 'KH/JA/212', 'KH/JA/213', 'KH/JA/214', 'KH/JA/215',\n",
    "                         'KH/JA/216', 'KH/JA/217', 'KH/JA/218', 'KH/JA/219', 'KH/JA/220', 'KH/JA/221', 'KH/JA/222', 'KH/JA/223',\n",
    "                         'KH/JA/224', 'KH/JA/225', 'KH/JA/226', 'KH/JA/227', 'KH/JA/228', 'KH/JA/229', 'KH/JA/230', 'KH/JA/231',\n",
    "                         'KH/JA/232', 'KH/JA/233', 'KH/JA/234', 'KH/JA/235', 'KH/JA/236', 'KH/JA/237', 'KH/JA/135', 'KH/JA/136',\n",
    "                         'KH/JA/137', 'KH/JA/138', 'KH/JA/139', 'KH/JA/140', 'KH/JA/141', 'KH/JA/142', 'KH/JA/143', 'KH/JA/148']\n",
    "\n",
    "# Remocve then from this list\n",
    "final_results = final_results[~final_results['kitchen_code'].isin(kitchen_to_be_removed)]\n",
    "\n",
    "## trasnform price into float\n",
    "final_results = final_results.loc[final_results['price'] != '.']\n",
    "final_results['price'] = final_results['price'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93eee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete grid of type_of_food, date, and kitchen_locality\n",
    "unique_foods = final_results[\"type_of_food\"].unique()\n",
    "unique_dates = ['01/07/2024', '15/07/2024', '01/08/2024', '15/08/2024',\n",
    "                '01/09/2024', '15/09/2024','01/10/2024', '15/10/2024', \n",
    "                '01/11/2024', '15/11/2024', '01/12/2024', '15/12/2024']\n",
    "unique_localities = kitchen_data[\"kitchen_locality\"].unique()\n",
    "\n",
    "complete_grid = pd.MultiIndex.from_product(\n",
    "    [unique_foods, unique_dates, unique_localities],\n",
    "    names=[\"type_of_food\", \"date\", \"kitchen_locality\"]\n",
    ").to_frame(index=False)\n",
    "complete_grid = complete_grid.dropna(subset=[\"kitchen_locality\"]).reset_index(drop=True)\n",
    "\n",
    "final_results_filled = final_results.copy()\n",
    "# Fill missing prices with group mean\n",
    "final_results_filled[\"price\"] = final_results_filled.groupby(\n",
    "    [\"kitchen_locality\", \"type_of_food\", \"date\"]\n",
    ")[\"price\"].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "final_results_filled = final_results_filled.drop_duplicates()\n",
    "\n",
    "# Merge the complete grid with the original data\n",
    "# Drop duplicates from final_results_filled\n",
    "final_results_filled = final_results_filled.drop_duplicates(\n",
    "    subset=[\"type_of_food\", \"date\", \"kitchen_locality\"]\n",
    ")\n",
    "\n",
    "# Ensure no mismatches in kitchen_locality values\n",
    "final_results_filled[\"kitchen_locality\"] = final_results_filled[\"kitchen_locality\"].str.strip()\n",
    "complete_grid[\"kitchen_locality\"] = complete_grid[\"kitchen_locality\"].str.strip()\n",
    "\n",
    "# Merge the complete grid with the final results\n",
    "df_full = complete_grid.merge(\n",
    "    final_results_filled[[\"type_of_food\", \"date\", \"price\", \"kitchen_locality\"]],\n",
    "    on=[\"type_of_food\", \"date\", \"kitchen_locality\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "##Save the data into excel\n",
    "df_full.to_excel('../output/clean_item_price_time.xlsx', index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9f5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cdbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

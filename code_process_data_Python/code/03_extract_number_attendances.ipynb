{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23799065",
   "metadata": {},
   "source": [
    "# Clean Attendance files\n",
    "\n",
    "The goal is to clean attendance files in order to extract information. We will complete information in the main kitchen file (kitchen_ids_cluster) but also develop a new excel file called cleaned_attendances.xslx to merge all the information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c16067",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a85473",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03d29c",
   "metadata": {},
   "source": [
    "### Clean attendances files month by month \n",
    "Due to different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the kitchen files\n",
    "kitchen_data = pd.read_excel('../output/kitchen_ids_cluster.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18928ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First focus on attendance of July\n",
    "##Open the file\n",
    "july_attendance = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet July 2024.xlsx')\n",
    "## Extract name of kitchen with existing data\n",
    "july_benef_data = july_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "\n",
    "## Now clean information in the july file\n",
    "# Select columns \n",
    "july_attendance = july_attendance.drop(['No.', 'State', 'Locality', 'District / Area', 'Number of Beneficiaries '], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "july_attendance_melted = july_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "july_attendance_melted['Date'] = pd.to_datetime(july_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "july_attendance_melted['Year'] = july_attendance_melted['Date'].dt.year\n",
    "july_attendance_melted['Month'] = july_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_july = july_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "# Ensure 'nb_meals' is numeric, coercing errors to NaN\n",
    "final_july['nb_meals'] = pd.to_numeric(final_july['nb_meals'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "merged_data = final_july.groupby(['Code'])['nb_meals'].mean().reset_index()\n",
    "\n",
    "## Join both data \n",
    "july_benef_data = july_benef_data.merge(merged_data, on='Code', how='left')\n",
    "july_benef_data = july_benef_data.rename(columns={\"nb_meals\": \"benef\", \"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "july_benef_data['Month'] = 7\n",
    "july_benef_data['Year'] = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1180dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second focus on attendance of August\n",
    "##Open the file\n",
    "aug_attendance = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet AUG 2024.xlsx')\n",
    "\n",
    "## Extract name of kitchen with existing data\n",
    "aug_benef_data = aug_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "\n",
    "## Now clean information in the july file\n",
    "# Select columns \n",
    "aug_attendance = aug_attendance.drop(['No.', 'State', 'Locality', 'District / Area', 'Number of Beneficiaries '], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "aug_attendance_melted = aug_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "aug_attendance_melted['Date'] = pd.to_datetime(aug_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "aug_attendance_melted['Year'] = aug_attendance_melted['Date'].dt.year\n",
    "aug_attendance_melted['Month'] = aug_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_aug = aug_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "# Ensure 'nb_meals' is numeric, coercing errors to NaN\n",
    "final_aug['nb_meals'] = pd.to_numeric(final_aug['nb_meals'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "merged_data = final_aug.groupby(['Code'])['nb_meals'].mean().reset_index()\n",
    "\n",
    "## Join both data \n",
    "aug_benef_data = aug_benef_data.merge(merged_data, on='Code', how='left')\n",
    "aug_benef_data = aug_benef_data.rename(columns={\"nb_meals\": \"benef\", \"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "aug_benef_data['Month'] = 8\n",
    "aug_benef_data['Year'] = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth focus on attendance of September -  2 files\n",
    "##Open the file\n",
    "sep_attendance_1 = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet Sep 2024.xlsx')\n",
    "sep_attendance_2 = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sep.xlsx')\n",
    "## Some have been double enter\n",
    "# Ensure column names are strings\n",
    "sep_attendance_1.columns = sep_attendance_1.columns.map(str)\n",
    "sep_benef_data = pd.DataFrame(sep_attendance_1['Code'])\n",
    "\n",
    "# Identify date columns and their corresponding \"Unnamed\" columns\n",
    "date_columns = [col for col in sep_attendance_1.columns if 'Unnamed' not in col and 'No.' not in col and 'Code' not in col and 'State' not in col and 'Locality' not in col and 'District / Area' not in col and 'Number of Beneficiaries ' not in col]\n",
    "unnamed_columns = [col for col in sep_attendance_1.columns if 'Unnamed:' in col]\n",
    "\n",
    "# Create a mapping of date columns to their corresponding \"Unnamed\" columns\n",
    "column_pairs = [(date, unnamed) for date, unnamed in zip(date_columns, unnamed_columns)]\n",
    "\n",
    "# Convert relevant columns to numeric, handling errors (non-numeric entries become NaN)\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    sep_attendance_1[date_col] = pd.to_numeric(sep_attendance_1[date_col], errors='coerce').fillna(np.nan)\n",
    "    sep_attendance_1[unnamed_col] = pd.to_numeric(sep_attendance_1[unnamed_col], errors='coerce').fillna(np.nan)\n",
    "\n",
    "# Sum the date columns with their corresponding \"Unnamed\" columns\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    sep_attendance_1[date_col] = sep_attendance_1[[date_col, unnamed_col]].max(axis=1)\n",
    "    sep_benef_data[date_col] = sep_attendance_1[[date_col, unnamed_col]].mean(axis=1)\n",
    "\n",
    "# # Drop the \"Unnamed\" columns after summing\n",
    "sep_attendance_1 = sep_attendance_1.drop(columns=unnamed_columns)\n",
    "## Remove added columns\n",
    "sep_attendance_2 = sep_attendance_2[sep_attendance_2.columns.drop(list(sep_attendance_2.filter(regex='Unnamed:')))]\n",
    "sep_attendance_2 = sep_attendance_2[sep_attendance_2['No'].notna()]\n",
    "sep_attendance_1 = sep_attendance_1[sep_attendance_1['No.'].notna()]\n",
    "## Concat both\n",
    "sep_attendance = pd.concat([sep_attendance_1,sep_attendance_2], axis=0, ignore_index=True)\n",
    "sep_benef_data = pd.concat([sep_benef_data,sep_attendance_2], axis=0, ignore_index=True)\n",
    "\n",
    "## Now clean information in the july file\n",
    "est_benef = sep_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "# Select columns \n",
    "sep_attendance = sep_attendance.drop(['No.', 'State', 'Locality', 'District / Area', 'Number of Beneficiaries ', 'No', 'Area'], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "sep_attendance_melted = sep_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "sep_benef_data = sep_benef_data.melt(id_vars=['Code'], var_name='Date', value_name='benef')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "sep_attendance_melted['Date'] = pd.to_datetime(sep_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "sep_attendance_melted['Year'] = sep_attendance_melted['Date'].dt.year\n",
    "sep_attendance_melted['Month'] = sep_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_sep = sep_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "# Ensure 'nb_meals' is numeric, coercing errors to NaN\n",
    "sep_benef_data['benef'] = pd.to_numeric(sep_benef_data['benef'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "sep_benef_data = sep_benef_data[['Code', 'benef']].groupby(['Code']).mean().reset_index()\n",
    "\n",
    "## Merge to have the estimated benef\n",
    "sep_benef_data = sep_benef_data.merge(est_benef, on='Code', how='left')\n",
    "sep_benef_data = sep_benef_data.rename(columns={\"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "sep_benef_data['Month'] = 9\n",
    "sep_benef_data['Year'] = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc91541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth focus on attendance of October -  2 files\n",
    "##Open the file\n",
    "oct_attendance_1 = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet Oct 2024.xlsx')\n",
    "oct_attendance_2 = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Oct.xlsx')\n",
    "\n",
    "## Some have been double enter\n",
    "# Ensure column names are strings\n",
    "oct_attendance_1.columns = oct_attendance_1.columns.map(str)\n",
    "oct_benef_data = pd.DataFrame(oct_attendance_1['Code'])\n",
    "\n",
    "# Identify date columns and their corresponding \"Unnamed\" columns\n",
    "date_columns = [col for col in oct_attendance_1.columns if 'Unnamed' not in col and 'No.' not in col and 'Code' not in col and 'State' not in col and 'Locality' not in col and 'District / Area' not in col and 'Number of Beneficiaries ' not in col]\n",
    "unnamed_columns = [col for col in oct_attendance_1.columns if 'Unnamed:' in col]\n",
    "\n",
    "# Create a mapping of date columns to their corresponding \"Unnamed\" columns\n",
    "column_pairs = [(date, unnamed) for date, unnamed in zip(date_columns, unnamed_columns)]\n",
    "\n",
    "# Convert relevant columns to numeric, handling errors (non-numeric entries become NaN)\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    oct_attendance_1[date_col] = pd.to_numeric(oct_attendance_1[date_col], errors='coerce').fillna(np.nan)\n",
    "    oct_attendance_1[unnamed_col] = pd.to_numeric(oct_attendance_1[unnamed_col], errors='coerce').fillna(np.nan)\n",
    "\n",
    "# Sum the date columns with their corresponding \"Unnamed\" columns\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    oct_attendance_1[date_col] = oct_attendance_1[[date_col, unnamed_col]].max(axis=1)\n",
    "    # Check if both columns have at least one non-null value\n",
    "    oct_benef_data[date_col] = oct_attendance_1[[date_col, unnamed_col]].mean(axis=1)\n",
    "\n",
    "# # Drop the \"Unnamed\" columns after summing\n",
    "oct_attendance_1 = oct_attendance_1.drop(columns=unnamed_columns)\n",
    "# Remove added columns\n",
    "oct_attendance_2 = oct_attendance_2[oct_attendance_2.columns.drop(list(oct_attendance_2.filter(regex='Unnamed:')))]\n",
    "oct_attendance_2 = oct_attendance_2[oct_attendance_2['No'].notna()]\n",
    "oct_attendance_1 = oct_attendance_1[oct_attendance_1['No.'].notna()]\n",
    "## Concat both\n",
    "oct_attendance = pd.concat([oct_attendance_1,oct_attendance_2], axis=0, ignore_index=True)\n",
    "oct_benef_data = pd.concat([oct_benef_data,oct_attendance_2], axis=0, ignore_index=True)\n",
    "\n",
    "## Now clean information in the july file\n",
    "est_benef = oct_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "# Select columns \n",
    "oct_attendance = oct_attendance.drop(['No.', 'State', 'Locality', 'District / Area', 'Number of Beneficiaries ', 'No', 'Area'], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "oct_attendance_melted = oct_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "oct_benef_data = oct_benef_data.melt(id_vars=['Code'], var_name='Date', value_name='benef')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "oct_attendance_melted['Date'] = pd.to_datetime(oct_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "oct_attendance_melted['Year'] = oct_attendance_melted['Date'].dt.year\n",
    "oct_attendance_melted['Month'] = oct_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_oct = oct_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "# Ensure 'benef' is numeric, coercing errors to NaN\n",
    "oct_benef_data['benef'] = pd.to_numeric(oct_benef_data['benef'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "oct_benef_data = oct_benef_data[['Code', 'benef']].groupby(['Code']).mean().reset_index()\n",
    "\n",
    "## Merge to have the estimated benef\n",
    "oct_benef_data = oct_benef_data.merge(est_benef, on='Code', how='left')\n",
    "oct_benef_data = oct_benef_data.rename(columns={\"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "oct_benef_data['Month'] = 10\n",
    "oct_benef_data['Year'] = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b53cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth focus on attendance of November -  2 files\n",
    "##Open the file\n",
    "nov_attendance_1 = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet Nov 2024.xlsx')\n",
    "nov_attendance_2 = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Nov.xlsx')\n",
    "\n",
    "## Some have been double enter\n",
    "# Ensure column names are strings\n",
    "nov_attendance_1.columns = nov_attendance_1.columns.map(str)\n",
    "nov_benef_data = pd.DataFrame(nov_attendance_1['Code'])\n",
    "\n",
    "# Identify date columns and their corresponding \"Unnamed\" columns\n",
    "date_columns = [col for col in nov_attendance_1.columns if 'Unnamed' not in col and 'No.' not in col and 'Code' not in col and 'State' not in col and 'Locality' not in col and 'District / Area' not in col and 'Number of Beneficiaries ' not in col]\n",
    "unnamed_columns = [col for col in nov_attendance_1.columns if 'Unnamed:' in col]\n",
    "\n",
    "# Create a mapping of date columns to their corresponding \"Unnamed\" columns\n",
    "column_pairs = [(date, unnamed) for date, unnamed in zip(date_columns, unnamed_columns)]\n",
    "\n",
    "# Convert relevant columns to numeric, handling errors (non-numeric entries become NaN)\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    nov_attendance_1[date_col] = pd.to_numeric(nov_attendance_1[date_col], errors='coerce').fillna(np.nan)\n",
    "    nov_attendance_1[unnamed_col] = pd.to_numeric(nov_attendance_1[unnamed_col], errors='coerce').fillna(np.nan)\n",
    "\n",
    "# Sum the date columns with their corresponding \"Unnamed\" columns\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    nov_attendance_1[date_col] = nov_attendance_1[[date_col, unnamed_col]].max(axis=1)\n",
    "    nov_benef_data[date_col] = nov_attendance_1[[date_col, unnamed_col]].mean(axis=1)\n",
    "\n",
    "# # Drop the \"Unnamed\" columns after summing\n",
    "nov_attendance_1 = nov_attendance_1.drop(columns=unnamed_columns)\n",
    "# Remove added columns\n",
    "nov_attendance_2 = nov_attendance_2[nov_attendance_2.columns.drop(list(nov_attendance_2.filter(regex='Unnamed:')))]\n",
    "nov_attendance_2 = nov_attendance_2[nov_attendance_2['No'].notna()]\n",
    "nov_attendance_1 = nov_attendance_1[nov_attendance_1['No.'].notna()]\n",
    "\n",
    "## Remove some data\n",
    "nov_attendance_1['Code'] = [code.replace(\"S\",\"\") for code in nov_attendance_1['Code']]\n",
    "nov_attendance_1['Code'] = [code.replace(\" \",\"\") for code in nov_attendance_1['Code']]\n",
    "nov_benef_data['Code'] = [str(code).replace(\"S\",\"\") for code in nov_benef_data['Code']]\n",
    "nov_benef_data['Code'] = [str(code).replace(\" \",\"\") for code in nov_benef_data['Code']]\n",
    "\n",
    "## Concat both\n",
    "nov_attendance = pd.concat([nov_attendance_1,nov_attendance_2], axis=0, ignore_index=True)\n",
    "nov_benef_data = pd.concat([nov_benef_data,nov_attendance_2], axis=0, ignore_index=True)\n",
    "\n",
    "## Extarct estimation data\n",
    "est_benef = nov_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "\n",
    "# Select columns \n",
    "nov_attendance = nov_attendance.drop(['No.', 'State', 'Localit', 'Locality', 'District / Area', 'Number of Beneficiaries ', 'No', 'Area'], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "nov_attendance_melted = nov_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "nov_benef_data = nov_benef_data.melt(id_vars=['Code'], var_name='Date', value_name='benef')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "nov_attendance_melted['Date'] = pd.to_datetime(nov_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "nov_attendance_melted['Year'] = nov_attendance_melted['Date'].dt.year\n",
    "nov_attendance_melted['Month'] = nov_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_nov = nov_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "\n",
    "# Ensure 'benef' is numeric, coercing errors to NaN\n",
    "nov_benef_data['benef'] = pd.to_numeric(nov_benef_data['benef'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "nov_benef_data = nov_benef_data[['Code', 'benef']].groupby(['Code']).mean().reset_index()\n",
    "\n",
    "## Merge to have the estimated benef\n",
    "nov_benef_data = nov_benef_data.merge(est_benef, on='Code', how='left')\n",
    "nov_benef_data = nov_benef_data.rename(columns={\"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "nov_benef_data['Month'] = 11\n",
    "nov_benef_data['Year'] = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth focus on attendance of November -  1 file\n",
    "##Open the file\n",
    "dec_attendance = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet Dec 2024.xlsx')\n",
    "\n",
    "# Ensure column names are strings\n",
    "dec_attendance.columns = dec_attendance.columns.map(str)\n",
    "dec_benef_data = pd.DataFrame(dec_attendance['Code'])\n",
    "\n",
    "# Identify date columns and their corresponding \"Unnamed\" columns\n",
    "date_columns = [col for col in dec_attendance.columns if 'Unnamed' not in col and 'No.' not in col and 'Code' not in col and 'State' not in col and 'Locality' not in col and 'District / Area' not in col and 'Number of Beneficiaries ' not in col]\n",
    "unnamed_columns = [col for col in dec_attendance.columns if 'Unnamed:' in col]\n",
    "\n",
    "# Create a mapping of date columns to their corresponding \"Unnamed\" columns\n",
    "column_pairs = [(date, unnamed) for date, unnamed in zip(date_columns, unnamed_columns)]\n",
    "\n",
    "# Convert relevant columns to numeric, handling errors (non-numeric entries become NaN)\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    dec_attendance[date_col] = pd.to_numeric(dec_attendance[date_col], errors='coerce').fillna(np.nan)\n",
    "    dec_attendance[unnamed_col] = pd.to_numeric(dec_attendance[unnamed_col], errors='coerce').fillna(np.nan)\n",
    "\n",
    "# Sum the date columns with their corresponding \"Unnamed\" columns\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    # Store the sum\n",
    "    dec_attendance[date_col] = dec_attendance[[date_col, unnamed_col]].max(axis=1)\n",
    "    dec_benef_data[date_col] = dec_attendance[[date_col, unnamed_col]].mean(axis=1)\n",
    "\n",
    "# # Drop the \"Unnamed\" columns after summing\n",
    "dec_attendance = dec_attendance.drop(columns=unnamed_columns)\n",
    "\n",
    "## Now clean information in the dec file\n",
    "## Extarct estimation data\n",
    "est_benef = dec_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "# Select columns \n",
    "dec_attendance = dec_attendance.drop(['No.', 'State', 'Locality', 'District / Area', 'Number of Beneficiaries '], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "dec_attendance_melted = dec_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "dec_benef_data = dec_benef_data.melt(id_vars=['Code'], var_name='Date', value_name='benef')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "dec_attendance_melted['Date'] = pd.to_datetime(dec_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "dec_attendance_melted['Year'] = dec_attendance_melted['Date'].dt.year\n",
    "dec_attendance_melted['Month'] = dec_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_dec = dec_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "# Ensure 'benef' is numeric, coercing errors to NaN\n",
    "dec_benef_data['benef'] = pd.to_numeric(dec_benef_data['benef'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "dec_benef_data = dec_benef_data[['Code', 'benef']].groupby(['Code']).mean().reset_index()\n",
    "\n",
    "## Merge to have the estimated benef\n",
    "dec_benef_data = dec_benef_data.merge(est_benef, on='Code', how='left')\n",
    "dec_benef_data = dec_benef_data.rename(columns={\"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "dec_benef_data['Month'] = 12\n",
    "dec_benef_data['Year'] = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth focus on attendance of November -  1 file\n",
    "##Open the file\n",
    "jan_attendance = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet Jan 2025.xlsx')\n",
    "\n",
    "# Ensure column names are strings\n",
    "jan_attendance.columns = jan_attendance.columns.map(str)\n",
    "jan_benef_data = pd.DataFrame(jan_attendance['Code'])\n",
    "\n",
    "# Identify date columns and their corresponding \"Unnamed\" columns\n",
    "date_columns = [col for col in jan_attendance.columns if 'Unnamed' not in col and 'No.' not in col and 'Code' not in col and 'State' not in col and 'Locality' not in col and 'District / Area' not in col and 'Number of Beneficiaries ' not in col]\n",
    "unnamed_columns = [col for col in jan_attendance.columns if 'Unnamed:' in col]\n",
    "\n",
    "# Create a mapping of date columns to their corresponding \"Unnamed\" columns\n",
    "column_pairs = [(date, unnamed) for date, unnamed in zip(date_columns, unnamed_columns)]\n",
    "\n",
    "# Convert relevant columns to numeric, handling errors (non-numeric entries become NaN)\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    jan_attendance[date_col] = pd.to_numeric(jan_attendance[date_col], errors='coerce').fillna(np.nan)\n",
    "    jan_attendance[unnamed_col] = pd.to_numeric(jan_attendance[unnamed_col], errors='coerce').fillna(np.nan)\n",
    "\n",
    "# Sum the date columns with their corresponding \"Unnamed\" columns\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    # Store the sum\n",
    "    jan_attendance[date_col] = jan_attendance[[date_col, unnamed_col]].max(axis=1)\n",
    "    jan_benef_data[date_col] = jan_attendance[[date_col, unnamed_col]].mean(axis=1)\n",
    "\n",
    "# # Drop the \"Unnamed\" columns after summing\n",
    "jan_attendance = jan_attendance.drop(columns=unnamed_columns)\n",
    "\n",
    "## Now clean information in the dec file\n",
    "## Extarct estimation data\n",
    "est_benef = jan_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "# Select columns \n",
    "jan_attendance = jan_attendance.drop(['No.', 'State', 'Locality', 'District / Area', 'Number of Beneficiaries '], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "jan_attendance_melted = jan_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "jan_benef_data = jan_benef_data.melt(id_vars=['Code'], var_name='Date', value_name='benef')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "jan_attendance_melted['Date'] = pd.to_datetime(jan_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "jan_attendance_melted['Year'] = jan_attendance_melted['Date'].dt.year\n",
    "jan_attendance_melted['Month'] = jan_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_jan = jan_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "# Ensure 'benef' is numeric, coercing errors to NaN\n",
    "jan_benef_data['benef'] = pd.to_numeric(jan_benef_data['benef'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "jan_benef_data = jan_benef_data[['Code', 'benef']].groupby(['Code']).mean().reset_index()\n",
    "\n",
    "## Merge to have the estimated benef\n",
    "jan_benef_data = jan_benef_data.merge(est_benef, on='Code', how='left')\n",
    "jan_benef_data = jan_benef_data.rename(columns={\"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "jan_benef_data['Month'] = 1\n",
    "jan_benef_data['Year'] = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afea163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth focus on attendance of November -  1 file\n",
    "##Open the file\n",
    "fev_attendance = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet Feb 2025.xlsx')\n",
    "\n",
    "# Ensure column names are strings\n",
    "fev_attendance.columns = fev_attendance.columns.map(str)\n",
    "fev_benef_data = pd.DataFrame(fev_attendance['Code'])\n",
    "\n",
    "# Identify date columns and their corresponding \"Unnamed\" columns\n",
    "date_columns = [col for col in fev_attendance.columns if 'Unnamed' not in col and 'No.' not in col and 'Code' not in col and 'State' not in col and 'Locality' not in col and 'District / Area' not in col and 'Number of Beneficiaries ' not in col]\n",
    "unnamed_columns = [col for col in fev_attendance.columns if 'Unnamed:' in col]\n",
    "\n",
    "# Create a mapping of date columns to their corresponding \"Unnamed\" columns\n",
    "column_pairs = [(date, unnamed) for date, unnamed in zip(date_columns, unnamed_columns)]\n",
    "\n",
    "# Convert relevant columns to numeric, handling errors (non-numeric entries become NaN)\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    fev_attendance[date_col] = pd.to_numeric(fev_attendance[date_col], errors='coerce').fillna(np.nan)\n",
    "    fev_attendance[unnamed_col] = pd.to_numeric(fev_attendance[unnamed_col], errors='coerce').fillna(np.nan)\n",
    "\n",
    "# Sum the date columns with their corresponding \"Unnamed\" columns\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    # Store the sum\n",
    "    fev_attendance[date_col] = fev_attendance[[date_col, unnamed_col]].max(axis=1)\n",
    "    fev_benef_data[date_col] = fev_attendance[[date_col, unnamed_col]].mean(axis=1)\n",
    "\n",
    "# # Drop the \"Unnamed\" columns after summing\n",
    "fev_attendance = fev_attendance.drop(columns=unnamed_columns)\n",
    "\n",
    "## Now clean information in the dec file\n",
    "## Extarct estimation data\n",
    "est_benef = fev_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "# Select columns \n",
    "fev_attendance = fev_attendance.drop(['No.', 'State', 'Locality', 'District / Area', 'Number of Beneficiaries '], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "fev_attendance_melted = fev_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "fev_benef_data = fev_benef_data.melt(id_vars=['Code'], var_name='Date', value_name='benef')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "fev_attendance_melted['Date'] = pd.to_datetime(fev_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "fev_attendance_melted['Year'] = fev_attendance_melted['Date'].dt.year\n",
    "fev_attendance_melted['Month'] = fev_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_fev = fev_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "# Ensure 'benef' is numeric, coercing errors to NaN\n",
    "fev_benef_data['benef'] = pd.to_numeric(fev_benef_data['benef'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "fev_benef_data = fev_benef_data[['Code', 'benef']].groupby(['Code']).mean().reset_index()\n",
    "\n",
    "## Merge to have the estimated benef\n",
    "fev_benef_data = fev_benef_data.merge(est_benef, on='Code', how='left')\n",
    "fev_benef_data = fev_benef_data.rename(columns={\"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "fev_benef_data['Month'] = 2\n",
    "fev_benef_data['Year'] = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c537c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth focus on attendance of November -  1 file\n",
    "##Open the file\n",
    "mar_attendance = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Daily Ops Jul-Mar/Attendance Sheet Mar2025.xlsx')\n",
    "\n",
    "# Ensure column names are strings\n",
    "mar_attendance.columns = mar_attendance.columns.map(str)\n",
    "mar_benef_data = pd.DataFrame(mar_attendance['Code'])\n",
    "\n",
    "# Identify date columns and their corresponding \"Unnamed\" columns\n",
    "date_columns = [col for col in mar_attendance.columns if 'Unnamed' not in col and 'No.' not in col and 'Code' not in col and 'State' not in col and 'Locality' not in col and 'District / Area' not in col and 'Number of Beneficiaries ' not in col]\n",
    "unnamed_columns = [col for col in mar_attendance.columns if 'Unnamed:' in col]\n",
    "\n",
    "# Create a mapping of date columns to their corresponding \"Unnamed\" columns\n",
    "column_pairs = [(date, unnamed) for date, unnamed in zip(date_columns, unnamed_columns)]\n",
    "\n",
    "# Convert relevant columns to numeric, handling errors (non-numeric entries become NaN)\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    mar_attendance[date_col] = pd.to_numeric(mar_attendance[date_col], errors='coerce').fillna(np.nan)\n",
    "    mar_attendance[unnamed_col] = pd.to_numeric(mar_attendance[unnamed_col], errors='coerce').fillna(np.nan)\n",
    "\n",
    "# Sum the date columns with their corresponding \"Unnamed\" columns\n",
    "for date_col, unnamed_col in column_pairs:\n",
    "    # Store the sum\n",
    "    mar_attendance[date_col] = mar_attendance[[date_col, unnamed_col]].max(axis=1)\n",
    "    mar_benef_data[date_col] = mar_attendance[[date_col, unnamed_col]].mean(axis=1)\n",
    "\n",
    "# # Drop the \"Unnamed\" columns after summing\n",
    "mar_attendance = mar_attendance.drop(columns=unnamed_columns)\n",
    "\n",
    "## Now clean information in the dec file\n",
    "## Extarct estimation data\n",
    "est_benef = mar_attendance[['Code', 'Number of Beneficiaries ']]\n",
    "# Select columns \n",
    "mar_attendance = mar_attendance.drop(['No.', 'State', 'Locality', 'District / Area', 'Number of Beneficiaries '], axis=1)\n",
    "# Melt the DataFrame to have 'Date' as a column\n",
    "mar_attendance_melted = mar_attendance.melt(id_vars=['Code'], var_name='Date', value_name='nb_meals')\n",
    "mar_benef_data = mar_benef_data.melt(id_vars=['Code'], var_name='Date', value_name='benef')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "mar_attendance_melted['Date'] = pd.to_datetime(mar_attendance_melted['Date'])\n",
    "\n",
    "# Extract Year and Month from the 'Date' column\n",
    "mar_attendance_melted['Year'] = mar_attendance_melted['Date'].dt.year\n",
    "mar_attendance_melted['Month'] = mar_attendance_melted['Date'].dt.month\n",
    "\n",
    "# Reorder columns\n",
    "final_mar = mar_attendance_melted[['Code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "\n",
    "# Ensure 'benef' is numeric, coercing errors to NaN\n",
    "mar_benef_data['benef'] = pd.to_numeric(mar_benef_data['benef'], errors='coerce')\n",
    "\n",
    "## In this case the nb_meals = nb_benefeciaries - because only one values\n",
    "mar_benef_data = mar_benef_data[['Code', 'benef']].groupby(['Code']).mean().reset_index()\n",
    "\n",
    "## Merge to have the estimated benef\n",
    "mar_benef_data = mar_benef_data.merge(est_benef, on='Code', how='left')\n",
    "mar_benef_data = mar_benef_data.rename(columns={\"Number of Beneficiaries \": \"est_benef\"})\n",
    "\n",
    "## Add month and year \n",
    "mar_benef_data['Month'] = 3\n",
    "mar_benef_data['Year'] = 2025\n",
    "\n",
    "print(len(final_mar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join the different final data \n",
    "final_data = pd.concat([final_july, final_aug, final_sep, \n",
    "                        final_oct, final_nov, final_dec, \n",
    "                        final_jan, final_fev, final_mar], axis=0, ignore_index=True)\n",
    "final_data = final_data.rename(columns={\"Code\": \"kitchen_code\"})\n",
    "final_data = final_data.drop_duplicates()\n",
    "final_data = final_data[final_data['kitchen_code'].notna()]\n",
    "final_data['kitchen_code'] = [code.replace(\"/MA/\",\"/JA/\") for code in final_data['kitchen_code']]\n",
    "final_data.to_excel('../output/attendances_cleaned.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join the different final data \n",
    "final_data = pd.concat([july_benef_data, aug_benef_data, sep_benef_data, \n",
    "                        oct_benef_data, nov_benef_data, dec_benef_data, \n",
    "                       jan_benef_data, fev_benef_data, mar_benef_data], axis=0, ignore_index=True)\n",
    "final_data = final_data.rename(columns={\"Code\": \"kitchen_code\"})\n",
    "final_data = final_data.drop_duplicates()\n",
    "final_data = final_data[final_data['kitchen_code'].notna()]\n",
    "final_data['kitchen_code'] = [code.replace(\"/MA/\",\"/JA/\") for code in final_data['kitchen_code']]\n",
    "##Remove data still not open\n",
    "##Kitchen not in service\n",
    "kitchen_to_be_removed = ['KH/JA/184', 'KH/JA/185', 'KH/JA/186', 'KH/JA/187', 'KH/JA/188', 'KH/JA/189', 'KH/JA/190', 'KH/JA/191',\n",
    "                         'KH/JA/192', 'KH/JA/193', 'KH/JA/194', 'KH/JA/195', 'KH/JA/196', 'KH/JA/197', 'KH/JA/198', 'KH/JA/199',\n",
    "                         'KH/JA/200', 'KH/JA/201', 'KH/JA/202', 'KH/JA/203', 'KH/JA/204', 'KH/JA/205', 'KH/JA/206', 'KH/JA/207',\n",
    "                         'KH/JA/208', 'KH/JA/209', 'KH/JA/210', 'KH/JA/211', 'KH/JA/212', 'KH/JA/213', 'KH/JA/214', 'KH/JA/215',\n",
    "                         'KH/JA/216', 'KH/JA/217', 'KH/JA/218', 'KH/JA/219', 'KH/JA/220', 'KH/JA/221', 'KH/JA/222', 'KH/JA/223',\n",
    "                         'KH/JA/224', 'KH/JA/225', 'KH/JA/226', 'KH/JA/227', 'KH/JA/228', 'KH/JA/229', 'KH/JA/230', 'KH/JA/231',\n",
    "                         'KH/JA/232', 'KH/JA/233', 'KH/JA/234', 'KH/JA/235', 'KH/JA/236', 'KH/JA/237', 'KH/JA/135', 'KH/JA/136',\n",
    "                         'KH/JA/137', 'KH/JA/138', 'KH/JA/139', 'KH/JA/140', 'KH/JA/141', 'KH/JA/142', 'KH/JA/143', 'KH/JA/148']\n",
    "\n",
    "# Remocve then from this list\n",
    "final_data = final_data[~final_data['kitchen_code'].isin(kitchen_to_be_removed)]\n",
    "final_data.to_excel('../output/benef_over_time.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cf9e5",
   "metadata": {},
   "source": [
    "## Clean incidents docuement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the incident file - manually filled\n",
    "df_incident = pd.read_excel('../../1. Data available/ISHTM_Hadhreen/Incidents/incidence_report_summary.xlsx')\n",
    "### Read ids_cluster \n",
    "kitchen_ids_cluster = pd.read_excel('../output/kitchen_ids_cluster.xlsx')\n",
    "##Only select the ones when the kitchen operations was hold\n",
    "df_incident = df_incident.loc[df_incident['operations_hold'] == 'yes']\n",
    "# Read final data excel file \n",
    "df_attendances = pd.read_excel('../output/attendances_cleaned.xlsx')\n",
    "\n",
    "## Now the goal is if the attences numbers are empty for the kitchen code between the two dates - we can fill the gap by 0 as no food deliveries where available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure date columns are in datetime format\n",
    "df_attendances['Date'] = pd.to_datetime(df_attendances['Date'])\n",
    "df_incident['incidence_date'] = pd.to_datetime(df_incident['incidence_date'])\n",
    "df_incident['end_date_hold'] = pd.to_datetime(df_incident['end_date_hold'])\n",
    "\n",
    "# Merge the datasets on 'kitchen_id'\n",
    "df_merged = df_attendances.merge(df_incident, on='kitchen_code', how='left')\n",
    "\n",
    "# Check if the date is within the hold period\n",
    "df_merged['on_hold'] = (df_merged['Date'] >= df_merged['incidence_date']) & \\\n",
    "                       (df_merged['Date'] <= df_merged['end_date_hold'])\n",
    "\n",
    "# Update 'number_of_benef' to 0 if it's within the hold period and currently empty (NaN)\n",
    "df_merged['nb_meals'] = df_merged.apply(\n",
    "    lambda row: 0 if pd.isna(row['nb_meals']) and row['on_hold'] else row['nb_meals'], axis=1\n",
    ")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_result = df_merged[['kitchen_code', 'Date', 'Month', 'Year', 'nb_meals']]\n",
    "df_result['kitchen_code'] = [code.replace(\"/MA/\",\"/JA/\") for code in df_result['kitchen_code']]\n",
    "df_result = df_result.dropna(subset=['kitchen_code'])\n",
    "\n",
    "df_result['nb_meals'] = df_result['nb_meals'].replace('\\xa0', '0', regex=True).astype(float)\n",
    "# Sort by 'nb_meals' to prioritize non-NaN rows\n",
    "df_result = df_result.sort_values(by=['nb_meals'], na_position='last')\n",
    "\n",
    "## Correct the number of benef for the kicthen KH/JA/159\n",
    "df_result.loc[(df_result['Date'] > '2024-12-01') & (df_result['kitchen_code'] == 'KH/JA/159'), 'nb_meals'] /= 5\n",
    "\n",
    "# Drop duplicates, keeping the first occurrence (non-NaN row)\n",
    "df_result = df_result.drop_duplicates(subset=['kitchen_code', 'Date'], keep='first')\n",
    "##Only complete the grid with kitchen with at least on date with information\n",
    "unique_kitchen = df_result['kitchen_code'].unique()\n",
    "unique_date = pd.date_range('2024-07-01','2025-04-01',freq='d')\n",
    "complete_grid = pd.MultiIndex.from_product(\n",
    "    [unique_date, unique_kitchen],\n",
    "    names=[\"date\", \"kitchen_code\"]\n",
    ").to_frame(index=False)\n",
    "\n",
    "complete_grid['Year'] = complete_grid['date'].dt.year\n",
    "complete_grid['Month'] = complete_grid['date'].dt.month\n",
    "\n",
    "df_result = pd.merge(complete_grid, df_result, left_on=['date', 'kitchen_code', 'Year', 'Month'], right_on=['Date', 'kitchen_code', 'Year', 'Month'], how='left')\n",
    "\n",
    "df_result = df_result[['date', 'kitchen_code', 'Year', 'Month', 'nb_meals']]\n",
    "\n",
    "##Kitchen not in service\n",
    "kitchen_to_be_removed = ['KH/JA/184', 'KH/JA/185', 'KH/JA/186', 'KH/JA/187', 'KH/JA/188', 'KH/JA/189', 'KH/JA/190', 'KH/JA/191',\n",
    "                         'KH/JA/192', 'KH/JA/193', 'KH/JA/194', 'KH/JA/195', 'KH/JA/196', 'KH/JA/197', 'KH/JA/198', 'KH/JA/199',\n",
    "                         'KH/JA/200', 'KH/JA/201', 'KH/JA/202', 'KH/JA/203', 'KH/JA/204', 'KH/JA/205', 'KH/JA/206', 'KH/JA/207',\n",
    "                         'KH/JA/208', 'KH/JA/209', 'KH/JA/210', 'KH/JA/211', 'KH/JA/212', 'KH/JA/213', 'KH/JA/214', 'KH/JA/215',\n",
    "                         'KH/JA/216', 'KH/JA/217', 'KH/JA/218', 'KH/JA/219', 'KH/JA/220', 'KH/JA/221', 'KH/JA/222', 'KH/JA/223',\n",
    "                         'KH/JA/224', 'KH/JA/225', 'KH/JA/226', 'KH/JA/227', 'KH/JA/228', 'KH/JA/229', 'KH/JA/230', 'KH/JA/231',\n",
    "                         'KH/JA/232', 'KH/JA/233', 'KH/JA/234', 'KH/JA/235', 'KH/JA/236', 'KH/JA/237', 'KH/JA/135', 'KH/JA/136',\n",
    "                         'KH/JA/137', 'KH/JA/138', 'KH/JA/139', 'KH/JA/140', 'KH/JA/141', 'KH/JA/142', 'KH/JA/143', 'KH/JA/148']\n",
    "\n",
    "# Remocve then from this list\n",
    "df_result = df_result[~df_result['kitchen_code'].isin(kitchen_to_be_removed)]\n",
    "\n",
    "df_result.to_excel('../output/attendances_cleaned_completed.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9863670",
   "metadata": {},
   "source": [
    "## Attendance Imputations due to closed kitchens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aceae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "df_attand = pd.read_excel('../output/attendances_cleaned_completed.xlsx')\n",
    "## Select only Jebel Awlia and Mayo area\n",
    "df_attand = df_attand.loc[df_attand['kitchen_code'].str.contains('KH/JA|KH/MA')]\n",
    "\n",
    "## Imput data\n",
    "# Step 1: Sort by kitchen_code and date to ensure temporal order\n",
    "df_attand = df_attand.sort_values(by=['kitchen_code', 'date'])\n",
    "\n",
    "# Step 2: Forward fill missing values (ignore zeros)\n",
    "df_attand['attendance_ffill'] = (\n",
    "    df_attand.groupby('kitchen_code')['nb_meals']\n",
    "    .transform(lambda x: x.replace(0, None).ffill())\n",
    ")\n",
    "\n",
    "# Step 3: Backward fill missing values (ignore zeros)\n",
    "df_attand['attendance_bfill'] = (\n",
    "    df_attand.groupby('kitchen_code')['nb_meals']\n",
    "    .transform(lambda x: x.replace(0, None).bfill())\n",
    ")\n",
    "\n",
    "# Step 4: Combine forward and backward fill\n",
    "df_attand['attendance_combined'] = df_attand['attendance_ffill'].fillna(\n",
    "    df_attand['attendance_bfill']\n",
    ")\n",
    "\n",
    "# Step 5: Preserve explicit zeros\n",
    "df_attand['est_benef'] = df_attand.apply(\n",
    "    lambda row: 0 if row['nb_meals'] == 0 else row['attendance_combined'], axis=1\n",
    ")\n",
    "\n",
    "# Step 6: Drop intermediate columns\n",
    "df_attand = df_attand.drop(columns=['attendance_ffill', 'attendance_bfill', 'attendance_combined'])\n",
    "\n",
    "#Save the data\n",
    "df_attand.to_excel('../output/attendances_completed_imputed.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4aa9c7",
   "metadata": {},
   "source": [
    "## Calculate percentage of attendacnes compared one to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "#Read Data\n",
    "df_attand = pd.read_excel('../output/attendances_completed_imputed.xlsx')\n",
    "## Select only Jebel Awlia and Mayo area\n",
    "df_attand = df_attand.loc[df_attand['kitchen_code'].str.contains('KH/JA|KH/MA')]\n",
    "\n",
    "## Imput data\n",
    "# Step 1: Sort by kitchen_code and date to ensure temporal order\n",
    "df_attand = df_attand.sort_values(by=['kitchen_code', 'date'])\n",
    "\n",
    "# Ensure the date column is in datetime format\n",
    "df_attand['date'] = pd.to_datetime(df_attand['date'])\n",
    "\n",
    "# Add a Month-Year column\n",
    "df_attand['Month-Year'] = df_attand['date'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Group by Kitchen_ID and Month-Year, summing up attendance\n",
    "monthly_data = df_attand.groupby(['kitchen_code', 'Month-Year'])['est_benef'].mean().reset_index()\n",
    "\n",
    "monthly_data.to_excel('../output/attendances_comparison_kitchens.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87012754",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8850126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attand = pd.read_excel('../output/attendances_completed_imputed.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beneficiary over time\n",
    "# Aggregate nb_meals by date\n",
    "nb_meals_time = df_attand.groupby('date')[['nb_meals', 'est_benef']].apply(lambda x: x.replace(0, np.nan).mean()).reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(nb_meals_time['date'].to_numpy(), nb_meals_time['nb_meals'].to_numpy())\n",
    "#plt.plot(nb_meals_time['date'].to_numpy(), nb_meals_time['nb_meals'].to_numpy(), label = 'Simple data cleaning')\n",
    "#plt.plot(nb_meals_time['date'].to_numpy(), nb_meals_time['est_benef'].to_numpy(), label = 'Data imputed')\n",
    "plt.legend(title ='Type of cleaning')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Meal served per day')\n",
    "plt.grid(axis='x')\n",
    "plt.xticks(rotation=45)\n",
    "# Save the figure to a PNG file\n",
    "plt.savefig('../visualization/nb_meals_trends_imputation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406da5cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get unique kitchen codes\n",
    "kitchen_codes = df_attand['kitchen_code'].unique()\n",
    "\n",
    "# Determine the grid size for subplots\n",
    "n_kitchens = len(kitchen_codes)\n",
    "n_cols = 4  # Number of columns for the grid\n",
    "n_rows = -(-n_kitchens // n_cols)  # Ceiling division for rows\n",
    "\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows), sharey=False, sharex=True)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot data for each kitchen_code\n",
    "for i, kitchen in enumerate(kitchen_codes):\n",
    "    ax = axes[i]\n",
    "    kitchen_data = df_attand[df_attand['kitchen_code'] == kitchen]\n",
    "    ax.plot(kitchen_data['date'].to_numpy(), kitchen_data['est_benef'].to_numpy(), marker='x', label=kitchen)\n",
    "    ax.plot(kitchen_data['date'].to_numpy(), kitchen_data['nb_meals'].to_numpy(), marker='o', label=kitchen, linestyle='None')\n",
    "    \n",
    "    ax.set_title(kitchen)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('nb_meals')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remove unused subplots if any\n",
    "for i in range(n_kitchens, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout and add a title\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure to a PNG file\n",
    "plt.savefig('../visualization/kitchen_nb_meals_trends.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data per day by category\n",
    "df_attand['category'] = df_attand['nb_meals'].apply(\n",
    "    lambda x: 'Closed' if x == 0 else ('Opened' if not pd.isna(x) else 'No Info')\n",
    ")\n",
    "\n",
    "# Aggregate counts per category per date\n",
    "daily_counts = df_attand.groupby(['date', 'category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure stacking order: Opened (green)  Closed (red)  No Info (grey)\n",
    "stack_order = ['Opened', 'Closed', 'No Info']\n",
    "daily_counts = daily_counts[stack_order]  # Reorder columns\n",
    "\n",
    "# Define colors for each category\n",
    "category_colors = {'Opened': 'darkgreen', 'Closed': 'red', 'No Info': 'white'}\n",
    "\n",
    "# Increase bar width and adjust x-axis labels\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "bars = daily_counts.plot(kind='bar', stacked=True, width=1.2,  # Thicker bars\n",
    "                         color=[category_colors[col] for col in stack_order], \n",
    "                         ax=ax, edgecolor='white')\n",
    "\n",
    "# Add a horizontal line at y = 111 (total number of kitchens available)\n",
    "total_kitchens = 56\n",
    "ax.axhline(y=total_kitchens, color='black', linestyle='dashed', linewidth=1.5, label='Maximum available kitchen \\n in Jebel Awlia')\n",
    "\n",
    "# Set x-axis ticks to every 10th date\n",
    "ax.set_xticks(range(0, len(daily_counts), 10))\n",
    "ax.set_xticklabels(daily_counts.index[::10].strftime('%Y-%m-%d'), rotation=45, fontsize=9)\n",
    "\n",
    "# Labels and Formatting\n",
    "ax.set_xlabel('Date', fontsize=10)\n",
    "ax.set_ylabel('Number of Kitchens', fontsize=10)\n",
    "#ax.set_title('Daily Kitchen Status in Jebel Awlia', fontsize=12)\n",
    "ax.legend(title='Kitchen Status', loc='upper right', fontsize=10)\n",
    "\n",
    "plt.yticks(fontsize=9)\n",
    "plt.grid(axis='y', linestyle='dashed', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/kitchen_status_barplot.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f187e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values to determine colors\n",
    "df_attand['color'] = df_attand['nb_meals'].apply(\n",
    "    lambda x: 'red' if x == 0 else ('darkgreen' if not pd.isna(x) else 'white')\n",
    ")\n",
    "\n",
    "# Prepare the plot\n",
    "fig, ax = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "# Loop through each kitchen_code\n",
    "for kitchen in df_attand['kitchen_code'].unique():\n",
    "    kitchen_data = df_attand[df_attand['kitchen_code'] == kitchen]\n",
    "    ax.scatter(\n",
    "        kitchen_data['date'],\n",
    "        [kitchen] * len(kitchen_data),\n",
    "        c=kitchen_data['color'],\n",
    "        s=10,\n",
    "        edgecolor='white'\n",
    "    )\n",
    "\n",
    "# Set x-axis ticks to every 5th date\n",
    "all_dates = pd.date_range(df_attand['date'].min(), df_attand['date'].max(), freq='D')\n",
    "reduced_dates = all_dates[::5]  # Select every 5th date\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=9)\n",
    "ax.set_ylabel('Kitchen Code (of existing kitchens in Jebel Awlia)', fontsize=9)\n",
    "ax.set_yticks(df_attand['kitchen_code'].unique())\n",
    "#ax.set_title('Information Availability by Kitchen and Date', fontsize=14)\n",
    "ax.set_xticks(reduced_dates)\n",
    "ax.set_xticklabels(reduced_dates.strftime('%Y-%m-%d'), rotation=45)\n",
    "ax.tick_params(axis='x', labelsize=8)\n",
    "ax.tick_params(axis='y', labelsize=8, rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/attendance_jebel_awlia.png', dpi=300)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d58a5a7",
   "metadata": {},
   "source": [
    "## Visualization benefeciary over time + estimated benef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2257f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benef = pd.read_excel('../output/benef_over_time.xlsx')\n",
    "df_benef = df_benef.dropna(subset=['kitchen_code'])\n",
    "## Select only JA and MA\n",
    "df_benef_JA  = df_benef.loc[df_benef['kitchen_code'].str.contains('KH/JA|KH/MA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea66762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benef = pd.read_excel('../output/benef_over_time.xlsx')\n",
    "df_benef = df_benef.dropna(subset=['kitchen_code'])\n",
    "## Select only JA and MA\n",
    "df_benef_JA  = df_benef.loc[df_benef['kitchen_code'].str.contains('KH/JA|KH/MA')]\n",
    "\n",
    "# ## Create data:\n",
    "df_benef_JA['Month_Half'] = pd.to_datetime(df_benef_JA['Year'].astype(str) + \n",
    "                                           '-' + df_benef_JA['Month'].astype(str) + '-01', format='%Y-%m-%d')\n",
    "\n",
    "df_benef_JA = df_benef_JA.groupby('Month_Half').agg({\n",
    "    'benef': 'mean',\n",
    "    'est_benef': 'mean',\n",
    "    'kitchen_code': 'nunique'  # Count unique kitchens\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f255347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attand = pd.read_excel('../output/attendances_completed_imputed.xlsx')\n",
    "# Generate the start date for each month (assuming 'Month' is in 'YYYY-MM' format)\n",
    "start_dates = pd.to_datetime(df_attand['Year'].astype(str) + '-' + \n",
    "                             df_attand['Month'].astype(str) + '-01', format='%Y-%m-%d')  # Start of the month\n",
    "# Create a 'Half' column: 1 for days 1-15, 2 for days 16-end of month\n",
    "df_attand['Half'] = df_attand['date'].dt.day.apply(lambda x: 1 if x <= 15 else 2)\n",
    "\n",
    "# Half-months column (1 for first half, 2 for second half)\n",
    "half_months = df_attand['Half']\n",
    "\n",
    "# Calculate the mid of the month (15th for the second half)\n",
    "dates = start_dates + pd.to_timedelta((half_months - 1) * 15, unit='D')\n",
    "\n",
    "#Convert Month numbers to strings\n",
    "months_map = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', \n",
    "              7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "df_attand['Month_str'] = df_attand['Month'].map(months_map)\n",
    "\n",
    "# Create a Half-Month Column\n",
    "df_attand['Month_Half'] = start_dates + pd.to_timedelta((half_months - 1) * 15, unit='D')\n",
    "\n",
    "# Aggregate benef by half-month\n",
    "benef_time_stats = df_attand.groupby(['Month', 'Month_Half'])['est_benef'].agg(['mean', 'std', 'count']).reset_index()\n",
    "benef_time_stats['ci_upper'] = benef_time_stats['mean'] + 1.96 * (benef_time_stats['std'] / np.sqrt(benef_time_stats['count']))\n",
    "benef_time_stats['ci_lower'] = benef_time_stats['mean'] - 1.96 * (benef_time_stats['std'] / np.sqrt(benef_time_stats['count']))\n",
    "benef_time_stats = benef_time_stats.sort_values('Month_Half')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "# Plot benef and est_benef\n",
    "ax1.plot(benef_time_stats['Month_Half'].to_numpy(), benef_time_stats['mean'].to_numpy(), \n",
    "         label='Actual avg. daily people served per kitchen', color='cornflowerblue', linestyle='--', marker='x')\n",
    "ax1.fill_between(benef_time_stats['Month_Half'].to_numpy(), benef_time_stats['ci_lower'].to_numpy(), benef_time_stats['ci_upper'].to_numpy(), \n",
    "                 color='cornflowerblue', alpha=0.2, label='95% confidence interval')\n",
    "\n",
    "#ax1.plot(benef_time['Month_str'].to_numpy(), benef_time['benef'].to_numpy(), label='Actual number of people served per day', marker='o')\n",
    "ax1.plot(df_benef_JA['Month_Half'].to_numpy(), df_benef_JA['est_benef'].to_numpy(), \n",
    "         label='Expected daily people served per kitchen', marker='s')\n",
    "\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Daily benefeciaries served per kitchen')\n",
    "ax1.grid(axis='x')\n",
    "\n",
    "# Secondary axis for kitchens open\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_benef_JA['Month_Half'].to_numpy(), df_benef_JA['kitchen_code'].to_numpy(), \n",
    "         label='Number of kitchens providing data on \\n daily number of expected attendances', color='gray', \n",
    "         linestyle='dashed', marker='^')\n",
    "ax2.set_ylabel('Number of Reporting Kitchens')\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(loc='center', bbox_to_anchor=(0.2, 1.15))\n",
    "ax2.legend(loc='center', bbox_to_anchor=(0.8, 1.15))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "#plt.title(\"Meals Served & Kitchens Open Over Time\")\n",
    "plt.savefig('../visualization/benef_over_time.jpg', dpi=700, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
